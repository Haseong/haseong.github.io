---
layout: post
title: "얀 르쿤의 월드 모델: 텍스트를 넘어 세계를 이해하는 AI"
date: 2025-11-01 15:26:27 +0900
author: 정하성
categories: [Blog]
tags: [large-language-models, llm, artificial-intelligence, ai-limitations, world-model, yan-lecun, language-understanding, physical-intelligence]
excerpt: "LLM은 방대한 텍스트 패턴을 흉내 내는 통계적 모델입니다. 하지만 실제 세계 이해와 물리적 직관이 매우 부족합니다. 이로 인해 오류와 환각 현상이 빈번히 발생합니다. 진정한 AI는 언어를 넘어 신체성과 추론 능력을 갖춰야 합니다."
banner_image: "/assets/images/posts/2025-11-01-fundamental-limitations-of-large-language-models.jpg"
---

![](/assets/images/posts/2025-11-01-fundamental-limitations-of-large-language-models.jpg)

챗GPT를 필두로 한 LLM은 놀라운 문장 생성 능력으로 전 세계를 열광시켰다. IT 산업부터 일상까지 LLM이 가져온 변화는 실로 크다. 그러나 진화론적 관점에서 보면 우리는 지금 흥미로운 역설과 마주하고 있다. 인간의 언어는 약 20만년 전 호모 사피엔스의 등장과 함께 진화하기 시작했다. LLM은 바로 이 20만년의 언어적 진화를 불과 수년 만에 구현해냈다고 할 수 있다. 방대한 텍스트 데이터로 훈련된 AI는 인간의 언어 패턴을 놀랍도록 정확하게 재현한다.

그러나 언어는 지능의 빙산 일각에 불과하다. 생명체가 몸을 움직이고, 세상을 지각하며, 물리적 환경과 상호작용하는 능력은 약 5억년 전 캄브리아기 대폭발 시기부터 진화해왔다. 시각, 촉각, 운동 제어, 공간 인식, 물리 법칙에 대한 직관적 이해는 언어보다 2,500배 더 긴 시간 동안 자연선택의 도가니에서 단련되었다. 얀 르쿤이 제시하는 월드 모델(World Model)은 바로 이 5억년 진화의 복잡도를 풀려는 시도다. 20만년의 언어를 정복한 AI가 이제 5억년의 신체성과 물리적 지능으로 나아가려 하는 것이다.

2025년 1월 다보스 세계경제포럼에서 메타의 수석 AI 과학자 얀 르쿤은 선언했다. "5년 내로 정신이 온전한 사람이라면 아무도 대규모 언어 모델을 AI 시스템의 핵심 구성요소로 사용하지 않을 것이다." 튜링상 수상자이자 딥러닝의 아버지 중 한 명인 그의 발언은 단순한 도발이 아니다. 그는 지난 수년간 일관되게 현재의 LLM과 트랜스포머 기반 AI가 "진정한 지능으로 가는 과도기적 기술"에 불과하다고 주장해왔다. 지금의 AI가 단지 방대한 텍스트 데이터를 통계적으로 흉내내고 있을 뿐, 실제 세상을 이해하거나 추론하지 못한다는 것이다. 그가 제시하는 대안인 월드 모델은 물리 세계를 이해하고 시뮬레이션할 수 있는 AI, 진정한 상식과 추론 능력을 갖춘 AI로 가는 길이다.

## 거대 언어 모델의 근본적 한계

LLM의 동작 원리는 다음에 올 가장 그럴듯한 단어를 맞히는 확률 예측에 지나지 않는다. 예컨대 "고양이가 나무 위에서 내려오지 못하고 있다"라는 상황을 설명하면, 언어 모델은 훈련된 텍스트에 기반해 "사람이 사다리를 가져와서 구해준다"와 같은 문장을 그럴싸하게 이어간다. 하지만 이 과정에서 AI는 실제로 고양이, 나무, 사다리라는 현실 개념을 이해하지 못한 채 그저 텍스트 상의 패턴을 따르고 있을 뿐이다.

이는 철학자 존 설이 제시한 중국어 방 논증과 유사하다. 중국어를 전혀 모르는 사람이 규칙집만 가지고 중국어 질문에 완벽한 답을 내놓을 수 있지만, 그가 중국어를 이해한다고 할 수 없듯이, AI가 단어를 조작해 그럴듯한 답을 내놓지만 그 의미를 진짜로 이해하는 것은 아니다. 결국 이러한 얕은 이해는 AI로 하여금 사소한 맥락 변화에도 엉뚱한 답을 하게 만들며, 우리가 흔히 말하는 환각 현상과 논리적 오류로 드러난다. 특히 참고문헌 생성 작업에서 GPT-3.5의 환각률은 39.6%, GPT-4는 28.6%에 달하며, Google Bard는 91.4%의 오류율을 보였다. 물론 작업 유형에 따라 환각률은 크게 달라지지만, 이는 LLM이 사실 확인이 필요한 정밀한 작업에서 신뢰성 문제를 겪고 있음을 보여준다.

르쿤의 수학적 분석은 이 문제를 명확히 한다. 토큰당 오류 확률을 ε라 할 때, N개 토큰을 생성하면 정답 확률은 (1-ε)^N으로 지수적으로 감소한다. 매번 토큰을 생성할 때마다 정답 집합에서 벗어날 확률이 누적되며, 이는 "지수적으로 발산하는 확산 과정"이다. 초기 실수가 더 큰 오류로 눈덩이처럼 불어나며, 모델은 스스로를 교정할 수 없다.

이러한 통계적 패턴 학습의 한계는 물리 세계에 대한 직관 부족으로 이어진다. 상식과 물리 세계에 대한 직관 부족은 LLM의 또 다른 큰 약점이다. "깃털과 볼링공을 높은 곳에서 동시에 떨어뜨리면 어느 쪽이 먼저 땅에 닿을까?"라는 질문에, 요즘의 언어 모델은 훈련된 교과서적 지식을 활용해 "진공 상태에서는 동시에, 공기 중에서는 볼링공이 먼저 떨어진다"고 답할 수 있다. 언뜻 보면 정답이지만, 사실 이는 물리 법칙을 이해해서 추론한 것이라기보다 그저 문헌에서 본 문장을 조합해낸 결과에 가깝다.

이 모델에게 실제로 두 물체를 떨어뜨리는 경험이나 중력에 대한 직관은 없다. 따라서 만약 환경이 조금만 달라지거나 새로운 변수가 등장하면 AI는 쉽게 혼란에 빠진다. 실제 로봇에게 "탁자 가장자리에 유리컵을 놓으면 어떻게 될까?"라고 물어보는 상황을 생각해보자. LLM은 "떨어져서 깨질 수 있다"는 식으로 말할 것이다. 하지만 이 역시 '탁자 끝=위험'이라는 단어상의 연관성을 흉내낸 것일 뿐, 실제로 로봇이 그 컵을 다룰 때 마찰력이나 표면의 기울기 같은 현실 세계의 수많은 변수를 고려한 판단은 아니다. 이처럼 물리적 세계에 대한 이해 부족은 LLM이 현실 환경에서 믿기 어려운 실수를 저지를 수 있는 근본 이유다.

물리적 이해의 부족은 추론과 계획 능력의 결여로도 나타난다. 인간은 문제를 해결하기 위해 상황을 논리적으로 분석하고, 여러 단계를 내다보며 계획을 세운다. 그러나 현세대 언어 모델은 사실상 "한 번에 한 단어씩 다음 단어를 만들어내는" 일에 특화되어 있을 뿐이다. 복잡한 상황에서 여러 조건을 고려해 계획을 수정해 가며 목표를 달성하는 능력, 즉 심리학자 대니얼 카너먼이 말한 시스템 2에 해당하는 느리고 심사숙고하는 사고 과정은 현재의 LLM으로는 구현하기 어렵다.

"친구들을 저녁 식사에 초대할 계획을 세워줘"라고 하면, LLM은 그럴듯한 할 일 목록을 나열할 수 있다. 하지만 진행 중에 "정작 재료가 부족하다"거나 "교통 정체로 장보러 가기 어려운 상황" 같은 새로운 제약을 추가하면 금세 답이 이상해지거나 막혀 버린다. 우리 인간이라면 이런 돌발 상황에서 배달 음식을 시킬지, 메뉴를 바꿀지 등 여러 대응책을 모색하며 계획을 유연하게 조정할 것이다. 반면 LLM은 그런 현실적 추론보다는 훈련된 문자 패턴 안에서만 맴돌기 때문에, 장기적인 계획이나 역동적 문제 해결에는 한계를 보인다.

이러한 한계들의 근본 원인은 텍스트 정보 자체의 본질적 한계에 있다. 르쿤의 계산에 따르면, GPT-3 수준의 모델이 학습하는 10조 토큰(2×10¹³ 바이트)은 인간이 하루 8시간씩 읽는다면 17만~40만 년이 걸리는 분량이다. 반면 4세 아동은 깨어있는 16,000시간 동안 시신경을 통해 약 10¹⁵ 바이트의 시각 정보를 받는다. 시각 정보가 텍스트보다 50배 많은 정보를 제공한다는 것이다.

더 중요한 것은 질적 차이다. 아동은 생후 4개월에 물체 영속성을, 6~9개월에 중력과 안정성 개념을, 10개월 이후 운동량 보존을 학습한다. 이 모든 것은 관찰을 통해서이며, 텍스트로는 포착할 수 없다. 인간 아이는 태어나고 몇 년이면 보고 듣고 만지면서 물체가 떨어지는 이유, 물이 흐르는 방식 같은 기본 물리 규칙을 터득하는데, 최신 AI는 수천 년치에 해당하는 텍스트를 공부하고도 이런 상식적 물리 감각 하나 없다. 그 결과 IQ는 천재보다 높아 보여도, 정작 로봇에게 "바닥의 물컵을 치우라"고 시키면 서투르게 움직이다가 컵을 엎질러뜨린다. 이처럼 인지와 행동 사이의 간극이 존재하는 한, AI는 현실 세계에서 인간 수준의 신뢰도를 갖기 어렵다.

## 월드 모델: 세상을 시뮬레이션하는 AI

이런 배경에서 르쿤이 미래 AI의 해법으로 제시한 개념이 바로 월드 모델이다. 월드 모델이란 한 마디로 "세상이 어떻게 작동하는지에 대한 AI의 내재적 시뮬레이션"이다. 다시 말해, 언어 텍스트로 표현된 지식만 가지고 답을 찾아내는 기존 방식에서 벗어나, AI 스스로가 세계의 상태를 예측하고 이해할 수 있는 내부 모델을 갖추게 하자는 구상이다.

이는 사람이 어떤 행동을 하기 전에 머릿속으로 결과를 그려보는 멘탈 모델(mental model)과 유사한 개념이다. 인간은 축구공이 굴러오는 모습을 보면 곧 이어 어린아이가 뛰어나올 수도 있음을 직감하고 미리 주의를 기울인다. 마찬가지로 월드 모델을 장착한 AI는 "도로로 공이 굴러나왔다"는 센서 관찰이 주어졌을 때 곧 "아이 등장 가능성이 높다” 라는 미래 상황을 시뮬레이션하고 선제 대응할 수 있어야 한다. 이처럼 과거에 본 패턴을 답습하는 수준을 넘어, 보지 못한 상황도 내부의 세계 이해를 통해 추론하고 대비하는 능력이 진정한 지능의 핵심이다.

르쿤은 2024년 10월 Hudson Forum에서 이를 명쾌하게 정의했다. "월드 모델은 세계가 어떻게 작동하는지에 대한 당신의 정신 모델이다. 당신이 취할 수 있는 행동을 상상하면, 월드 모델이 그 행동의 효과를 예측한다." 기술적으로는 주어진 관측 x(t), 이전 상태 s(t), 행동 a(t), 잠재 변수 z(t)가 있을 때, 월드 모델은 h(t) = Enc(x(t))를 계산하고 s(t+1) = Pred(h(t), s(t), z(t), a(t))를 예측하는 시스템이다.

월드 모델 개념의 중요한 특징은 학습 데이터의 다양성이다. 지금까지의 언어 모델은 세상의 지식을 문자로 요약한 텍스트만 입력받았다. 하지만 월드 모델을 구축하려면 텍스트 너머의 세상이 필요하다. 르쿤은 "AI도 인간처럼 텍스트뿐 아니라 영상, 음성, 물리적 환경을 함께 경험하며 세상을 배워야 한다"고 강조한다.

아이가 세상을 이해할 때 오감을 총동원하듯, 월드 모델 기반 AI는 멀티 모달 데이터로부터 학습한다. 실제 영상과 음향, 로봇 센서로 받은 촉각 정보까지 통합하여, 물체들의 움직임과 상호작용, 물리 법칙의 원리를 스스로 터득하도록 만드는 것이다. 이렇게 해야만 AI가 "텍스트에 없는 지식"까지 내면화할 수 있다.

실제 현실에는 글로 쓰이지 않은 정보가 훨씬 많다. 예를 들어 귤을 까먹는 방법을 글로 읽을 수도 있지만, 향과 촉감을 느끼며 귤을 직접 까봐야 얻는 학습이 있다. 월드 모델은 이러한 실세계 경험의 학습을 AI에 부여하려는 시도이다.

월드 모델은 기존 접근법과 근본적으로 다르다. 생성 모델(MAE, Diffusion)은 모든 픽셀이나 토큰을 예측하려 하지만, 월드 모델은 추상적 표현을 예측한다. 바람에 흔들리는 나뭇잎의 세부사항은 예측 불가능하며 예측할 필요도 없다. 중요한 것은 고수준 의미론적 특징이다.

대조 학습(SimCLR, MoCo)은 증강에 대한 불변성을 학습하며 표현을 단일 지점으로 축소하지만, 월드 모델은 예측을 학습하며 공간과 시간 정보를 유지한다. 수작업 증강이 필요 없고 더 유연한 표현을 제공한다. 자기회귀 모델(GPT)은 다음 토큰을 순차적으로 예측하지만, 월드 모델은 여러 규모와 위치의 표현을 동시에 예측한다. 불확실성을 모델링하고 여러 미래를 다룰 수 있다.

## JEPA: 월드 모델의 핵심 아키텍처

월드 모델의 비전을 구체화한 핵심 아키텍처가 바로 JEPA(Joint Embedding Predictive Architecture, 조인트 임베딩 예측 아키텍처)다. 2022년 6월 발표된 "자율 기계 지능으로 가는 길"이라는 논문에서 처음 제안되었다. JEPA의 핵심 혁신은 픽셀이나 토큰 공간이 아닌 표현 공간에서 예측한다는 것이다.

기본 구조는 세 가지 주요 모듈로 구성된다. 컨텍스트 인코더는 이미지에서 마스킹되지 않은 영역을 처리하는 모듈로, Vision Transformer를 기반으로 구현되어 있다. 타겟 인코더는 마스킹된 영역의 실제 내용을 표현으로 변환한다. 이 인코더는 컨텍스트 인코더의 가중치를 천천히 따라가도록 업데이트되는데, 이는 학습 과정에서 모델이 의미 없는 동일한 값만 출력하는 붕괴 문제를 방지한다. 예측기는 보이는 부분의 표현을 받아 특정 위치의 가려진 내용을 예측하는데, 이때 '어느 위치를 예측해야 하는지'에 대한 정보를 함께 입력받는다.

JEPA는 불확실성을 두 가지 방식으로 처리한다. 첫째, 인코더 불변성이다. 인코더는 인코딩 과정에서 무관하거나 예측 불가능한 세부사항을 버린다. 표현은 예측 가능한 고수준 의미만 포착한다. 둘째, 잠재 변수 예측기다. 잠재 변수 z는 관측 불가능한 요인을 나타낸다. z를 변화시켜 여러 그럴듯한 예측을 생성할 수 있다. 예를 들어 비디오에서 가려진 물체가 어느 방향으로 움직일지를 z가 표현할 수 있다.

계층적 JEPA(H-JEPA)는 서로 다른 추상화 수준에서 예측한다. JEPA-1은 단기적이고 상세한 예측을 위해 고차원 표현과 작은 시간 지평을 사용한다. JEPA-2는 장기적이고 추상적인 예측을 위해 저차원 표현과 긴 시간 지평을 사용하며 계획을 위한 의미론적 개념을 포착한다.

JEPA의 학습 방법은 자기지도 학습(Self-Supervised Learning)에 기반한다. 이는 입력의 일부로부터 다른 부분을 예측하여 레이블 없는 데이터로부터 학습하는 방식이다. 인간과 동물이 수동 관찰을 통해 학습하는 것과 유사하다. 아기는 생후 4개월에 물리 법칙을 배운다. 레이블 없는 데이터가 레이블 있는 데이터보다 훨씬 풍부하며, 이를 통해 "상식", 즉 세계 작동 방식에 대한 기본 이해를 획득할 수 있다.

JEPA의 자기지도 학습 방식은 기존 방법들과 차별화된다. 대조 학습(SimCLR, MoCo, SwAV)은 증강된 뷰 간 유사도를 최대화하고 다른 샘플과의 거리를 최대화한다. 강력한 의미론적 표현을 제공하지만 수작업 증강이 필요하고, 표현을 단일 지점으로 축소하며, 증강 선택으로 인한 편향이 발생할 수 있다.

마스크 오토인코더(MAE)는 패치를 마스킹하고 픽셀을 재구성한다. 구현이 간단하고 증강이 불필요하지만, 예측 불가능한 픽셀 수준 세부사항에 용량을 낭비하고, 재구성 타겟이 너무 저수준이며, 의미론적 이해를 직접 최적화하지 않는다.

JEPA는 이 두 접근법의 장점을 결합한다. 수작업 증강이 불필요하고, 표현 공간에서 직접 예측하며, 공간과 시간 구조를 유지하고, 더 효율적인 훈련을 가능케 한다. 특히 비디오와 멀티모달 데이터 처리에서 강점을 보인다. 시간적 역학이 인과관계와 물리를 드러내기 때문이다. 인간이 주로 움직임 관찰을 통해 물리를 학습하는 것처럼, V-JEPA는 마스킹된 비디오 표현을 예측하며 세밀한 물체 상호작용을 처리한다.

## 에너지 기반 모델과 신경과학적 토대

JEPA의 이론적 토대는 에너지 기반 모델(Energy-Based Model, EBM)이다. 에너지 기반 모델은 변수 간 의존성을 각 구성에 스칼라 에너지 값을 할당하여 포착한다. 낮은 에너지는 호환 가능하거나 그럴듯한 구성을, 높은 에너지는 비호환이거나 있을 법하지 않은 구성을 의미한다. 수학적으로 에너지 함수 F: X × Y → R이 주어지면, 추론은 ŷ = argmin_y F(x,y)로 표현된다.

흥미롭게도 이러한 에너지 최소화 접근법은 신경과학의 중요한 이론과 깊은 연결을 맺고 있다. 영국 UCL의 신경과학자 프리스턴이 2006년경부터 제시한 자유에너지원리(Free Energy Principle)는 뇌를 "세계를 예측하는 생성모델"로 보고, 생명체가 환경의 불확실성과 놀라움을 최소화하려는 시스템이라고 정의한다.

프리스턴의 자유에너지는 단순히 물리학적 에너지가 아니라, 예측 오차와 모델 복잡도의 합으로 정의되는 정보이론적 양이다. 기본 가정은 모든 생명체가 자신이 속한 환경을 "모델링"하며, 이 모델이 실제 입력과 어긋날 때(즉 놀라움이 발생할 때) 내부 상태를 조정하여 오차를 최소화한다는 것이다. 수학적으로는 F = D_KL(q(s)¦p(s¦o)) - ln p(o)로 표현되며, 이는 자유에너지를 "내부 상태 q(s)"와 "외부 세계 p(s¦o)"의 차이(KL divergence)로 정의한다.

프리스턴은 이 원리를 확장해 능동적 추론이라는 행동이론으로 발전시켰다. 지각(Perception)은 내부 모델을 조정하여 감각 입력과의 오차를 줄이고, 행동(Action)은 세계를 바꾸어 예측이 맞도록 만든다. 결국 "감각 – 예측 – 행동"이 하나의 순환 구조로 통합된다.

르쿤의 에너지 기반 모델과 프리스턴의 자유에너지 원리는 놀랍도록 유사한 철학적 토대를 공유한다. 둘 다 시스템이 특정 종류의 "에너지"를 최소화하려 한다고 본다. 둘 다 예측과 오차 최소화를 강조한다. 둘 다 생성 모델의 중요성을 인식한다. 르쿤의 월드 모델이 세계를 내부적으로 시뮬레이션하는 것처럼, 프리스턴의 뇌 모델도 세계의 생성 모델을 구축하고 유지한다.

차이점도 있다. 프리스턴의 이론은 생물학적 시스템, 특히 뇌의 작동 원리를 설명하려는 신경과학적 틀이며, 베이지안 추론에 깊이 뿌리박고 있다. 반면 르쿤의 접근은 인공지능 시스템 설계를 위한 공학적 틀이며, 확률 모델의 한계(분배 함수 계산의 어려움)를 극복하려 한다. 그러나 두 접근법 모두 지능 시스템이 월드 모델을 통해 불확실성을 줄이고 예측을 개선하는 방향으로 작동한다는 핵심 통찰을 공유한다.

르쿤이 확률 모델보다 에너지 기반 모델을 선호하는 이유는 실용적이다. 첫째, 정규화가 불필요하다. 확률 모델은 P(y¦x) = exp(-βF(x,y)) / ∫exp(-βF(x,y'))dy'를 요구하며, 분모인 분배 함수는 고차원에서 다루기 어렵다. 에너지 기반 모델은 이를 회피하며 상대적 에너지만 필요하고 절대 확률은 필요 없다.

둘째, 의사결정에 더 적합하다. "의사결정을 하려면 확률은 쓸모없다." 시스템은 행동을 선택해야 하며 확률 분포를 출력할 필요가 없다. 가장 낮은 에너지 옵션만 찾으면 된다. 셋째, 얇은 다양체를 처리한다. 실제 데이터는 고차원 공간의 얇은 다양체에 놓이는 경우가 많다. 에너지 기반 모델은 경사 하강법에 적합한 매끄러운 에너지 표면을 가질 수 있다.

에너지 기반 모델을 훈련할 때 가장 조심해야 할 것은 붕괴 현상이다. 이는 모델의 에너지 함수가 모든 입력에 대해 비슷하게 낮은 값을 출력하게 되어, 결과적으로 아무것도 구별하지 못하는 상태를 말한다. 구체적인 예를 들어보자. 고양이 사진과 자동차 사진을 구별하는 모델을 훈련한다고 가정하자. 정상적인 모델이라면 고양이 사진에는 낮은 에너지를, 자동차 사진에는 높은 에너지를 부여해야 한다. 그런데 붕괴가 발생하면 둘 다 에너지 0.1을 출력하는 식으로, 모든 이미지에 비슷한 값을 주게 된다. 이렇게 되면 모델은 사실상 쓸모가 없다. 르쿤은 이 문제를 해결하기 위해 두 가지 제약을 동시에 적용하는 정규화 방법을 제안한다.

첫 번째 제약은 잠재 변수의 정보 용량 제한이다. 모델 내부의 표현 공간이 담을 수 있는 정보량에 한계를 둠으로써, 모델이 입력 데이터를 통째로 암기하는 대신 핵심적인 특징만 추출하도록 강제한다. 이는 과적합을 방지하고 일반화 성능을 높인다.

두 번째 제약은 낮은 에너지 영역의 부피 제한이다. 에너지 공간에서 낮은 값을 가질 수 있는 영역의 크기를 의도적으로 좁게 만든다. 이렇게 하면 모델이 모든 입력에 낮은 에너지를 마구 부여하는 대신, 정말로 좋은 입력에만 선택적으로 낮은 에너지를 할당하게 된다.

이 접근법의 큰 장점은 확장성이다. 이미지나 비디오처럼 차원이 매우 높은 데이터를 다룰 때, 기존의 많은 정규화 방법들은 계산이 복잡해지거나 효과가 떨어지는 문제가 있다. 하지만 르쿤의 방법은 고차원 공간에서도 안정적이고 효율적으로 작동한다. 이러한 원리를 실제로 구현한 대표적인 기법이 VIC-Reg(Variance-Invariance-Covariance Regularization, 분산-불변-공분산 정규화)이다. VIC-Reg은 세 가지 요소를 통해 위에서 설명한 제약들을 구체화한다.

## 월드 모델의 실제 구현과 미래

르쿤의 이론적 비전은 이미 구체적인 구현으로 이어지고 있다. 메타는 2023년 I-JEPA를 시작으로 2024년 V-JEPA, 2025년 V-JEPA 2를 연속 발표하며 비디오 이해 능력을 급속도로 향상시켰다. V-JEPA는 마스킹된 비디오 프레임의 추상 표현을 예측하도록 훈련되며, 물체 간 상호작용과 물리적 역학을 이해하는 능력을 보여준다. 특히 주목할 점은 레이블 없는 비디오만으로도 물리 법칙을 학습한다는 것이다. 이는 인간 아이가 세상을 관찰하며 중력과 운동량을 터득하는 과정과 유사하다.

Google DeepMind의 Genie 3도 유사한 방향으로 진화하고 있다. 단일 이미지로부터 상호작용 가능한 3D 환경을 생성하며, 사용자의 행동에 반응하는 일관된 물리 시뮬레이션을 구현했다. 이는 월드 모델이 단순한 예측을 넘어 실제 상호작용 가능한 세계를 만들어낼 수 있음을 보여준다. DreamerV3는 강화학습과 월드 모델을 결합하여 Minecraft부터 로봇 제어까지 다양한 도메인에서 뛰어난 성능을 달성했다. 에이전트가 상상 속 시뮬레이션에서 먼저 행동을 계획한 후 실제 환경에 적용하는 방식이다.

이러한 실제 구현들은 월드 모델이 더 이상 먼 미래의 이야기가 아님을 증명한다. 메타는 JEPA 구현체를 오픈소스로 공개하고 있으며, 이를 통해 연구 커뮤니티가 빠르게 성장하고 있다. 기술적 장벽도 점차 낮아지고 있다.

2024~2025년은 AI 업계에 중요한 전환점이 되고 있다. "스케일링의 시대"가 끝나고 "경이와 발견의 시대"가 시작되었다는 일리야 서츠케버의 선언은 상징적이다. 한때 "더 크면 더 좋다"의 대표 주자였던 그조차 NeurIPS 2024에서 "우리가 아는 사전 훈련은 의심할 여지 없이 끝날 것"이라고 말했다. OpenAI의 샘 알트먼도 "또 다른 돌파구가 필요하다"고 인정하며, 사전 훈련 스케일링만으로는 AGI에 불충분함을 시인했다.

Google DeepMind의 데미스 하사비스는 더욱 명확하다. "우리는 단순한 언어 모델이 아닌 월드 모델을 원한다." Gemini는 이 비전을 구현하기 위해 네이티브 멀티모달 모델로 설계되었으며, AlphaGo 스타일의 강화학습과 트리 탐색을 통합했다. 이는 Project Astra라는 범용 디지털 어시스턴트로 구체화되고 있다.

흥미로운 점은 리더들이 공개적으로 다른 입장을 취하면서도 실제 작업은 점점 수렴하고 있다는 것이다. OpenAI는 추론 능력을 강화하고, DeepMind는 뉴로심볼릭 시스템을 구축하며, 메타는 월드 모델을 개발하고, Anthropic은 테스트 타임 컴퓨트를 탐구한다. 모두가 멀티모달의 중요성, 계획과 추론의 필요성, 물리 세계 이해의 중요성에 동의한다. 다만 그 경로가 다를 뿐이다.

패러다임의 전환은 명확하다. 사전 훈련 스케일링에서 테스트 타임 컴퓨트로, 파라미터 수에서 추론 깊이로, 데이터 양에서 데이터 품질로 초점이 이동하고 있다. 이는 "더 크게"에서 "더 스마트하게"로의 전환이며, 월드 모델은 이러한 흐름의 핵심에 있다.

이러한 변화는 IT 전문가에게 구체적 함의를 지닌다. 단기적으로(2025~2027년)는 LLM 전문성이 여전히 가치 있다. 현재 LLM이 실용 AI를 지배하며, 언어 작업에서 계속 개선될 것이다. RAG, 외부 도구 통합, 하이브리드 접근법도 성숙할 것이다. 이 시기에는 JEPA 기술의 지속적 성장과 초기 상업적 적용이 시작되지만, 언어 분야에서는 여전히 LLM이 우위를 점할 것이다.

그러나 중장기적으로(2028~2030년)는 월드 모델 기술이 결정적으로 중요해진다. 잠재적 패러다임 전환이 일어나고, 하이브리드 접근법이 본격 출현하며, 특히 로봇공학, 시뮬레이션, 자율주행 같은 물리 AI 적용 분야에서 월드 모델이 핵심 기술이 될 것이다.

## **지능의 본질을 향한 여정**

얀 르쿤의 월드 모델 비전은 AI로 가는 길에 대한 근본적 재상상을 나타낸다. 그의 JEPA 아키텍처는 현재 LLM 패러다임에 직접 도전하며, 진정한 지능은 단순히 텍스트 패턴을 학습하는 것이 아니라 세계가 작동하는 방식 자체를 이해해야 한다고 주장한다. 관찰로부터 학습하고, 추상 공간에서 예측하며, 잠재 변수를 통해 불확실성을 처리하고, 시간 규모에 걸친 계층적 추론을 수행하며, 언어를 넘어 물리 세계를 이해하는 AI 말한다.

르쿤의 에너지 기반 접근법이 프리스턴의 자유에너지원리와 공명한다는 사실은 특히 의미심장하다. 신경과학과 인공지능이 "에너지 최소화를 통한 예측 오류 감소"라는 동일한 원리로 수렴하고 있다는 것은, 이것이 지능의 근본 원리일 가능성을 시사한다. 생물학적 뇌와 인공신경망이 모두 월드 모델을 구축하고, 놀라움을 최소화하며, 예측을 개선하는 방향으로 작동한다면, 우리는 진정한 지능의 본질에 한 걸음 더 다가간 것이다.

몇 가지는 확실하다. 현재 LLM의 한계는 명백하다. 환각 문제, 추론 불일치, 물리적 이해 부족, 계획 실패는 잘 알려져 있다. 거의 모든 AI 리더가 멀티모달의 중요성과 어떤 형태로든 계획 및 추론이 필요하다는 점에 동의한다. 텍스트만으로는 불충분하며, 시각, 비디오, 오디오 데이터와 공간 이해가 체화된 AI에 필수적이다.

미래는 단일 승자보다 여러 접근법의 요소를 종합한 형태일 가능성이 높다. 르쿤이 옳든 틀리든, 그의 비전은 이미 중요한 역할을 했다. AI 커뮤니티가 현재 접근법의 한계를 직시하고 대안을 진지하게 탐구하도록 강제했기 때문이다. 그것만으로도 패러다임을 바꾸고 있다.

IT 전문가로서 우리는 이 전환기에 양쪽 세계를 모두 이해하고, 기술적 유연성을 유지하며, 진정한 지능으로 가는 다양한 경로를 탐색할 준비를 해야 한다. 진화가 단일 경로가 아니라 여러 실험의 결과였듯이, AI의 미래도 그러할 것이다. 20만년의 언어를 정복한 AI가 이제 5억년의 물리적 지능으로 나아가는 이 여정에서 우리는 목격자이자 참여자가 될 것이다.

## 참고 자료

[A Path Towards Autonomous Machine Intelligence](https://openreview.net/forum?id=BZ5a1r-kVsf)

[I-JEPA: The first AI model based on Yann LeCun's vision for more human-like AI](https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/)

[V-JEPA: The next step toward advanced machine intelligence](https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/)

[V-JEPA 2 world model and new benchmarks for physical reasoning](https://ai.meta.com/research/publications/v-jepa-2/)

[Genie 3: A new frontier for world models](https://deepmind.google/discover/blog/)

[The Free Energy Principle: A Unified Brain Theory?](https://www.nature.com/articles/nrn2787)

[Active Inference: A Process Theory,](https://direct.mit.edu/neco/article-abstract/29/1/1/8234/Active-Inference-A-Process-Theory)

[DreamerV3: Mastering Diverse Domains through World Models,](https://www.nature.com/articles/)

[Tech leaders eye world models as link to smarter AI,](https://www.ibm.com/think/)

[Meta's Yann LeCun predicts 'new paradigm of AI architectures' within 5 years](https://techcrunch.com/)